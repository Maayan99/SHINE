# Config for the LoRA fine-tuning experiment.
# Self-contained: no Hydra defaults inheritance (avoids path issues when run from experiments/).
# All settings mirror Qwen3-8B.yaml; add `lora_finetune` section at the bottom.

name: 8gpu_8lora_128metalora_lr5e-5_grouppretrain_1150   # checkpoint name to load from

# Which checkpoint stage to load
test_global_step: "epoch-1"   # pretrain checkpoint  (use "epoch-2" for IFT)
checkpoint_stage: "train"      # "pretrain" | "train" (ift)

run:
  seed: 42
  device: cuda  # use mps for local Mac development

pretrain:
  completion_freq: 0.5
  max_completion_ratio: 0.3
  min_completion_ratio: 0.1

model:
  lora_r: 8
  metalora_r: 128
  ift_additional_metalora_r: -1
  num_mem_token: ${num_mem_token}
  metamodel_class_path: "LoraQwen.LoraQwen3ForCausalLM"
  config_class_path: "LoraQwen.Qwen3Config"
  tokenizer_from: "./models/Qwen3-8B"
  model_from: "./models/Qwen3-8B"

metanetwork:
  type: "transformer"
  method: "rl"
  transformer_cfg:
    encoder_cfg:
      d_model: 4096
      nhead: 32
      dim_feedforward: 8192
      dropout: 0
      activation: gelu
      layer_norm_eps: 0.00001
      batch_first: True
      norm_first: False
      bias: True
    couple_encoder_cfg:
      d_model: 4096
      nhead: 32
      dim_feedforward: 8192
      dropout: 0
      activation: gelu
      layer_norm_eps: 0.00001
      batch_first: True
      norm_first: False
      bias: True
    layer_transformer_first: True
    mean_pool_size: 1
    num_layers: 4
    couple_num_layers: 0
    scale: 0.001
  linear_cfg:
    num_layers: 4
    linear_hidden_dim: 8192
    scale: 0.001
    bias: false
  linear_gate_cfg:
    num_layers: 4
    linear_hidden_dim: 8192
    scale: 0.001
    bias: false

test:
  source: squad             # dataset to evaluate on: squad | hotpotqa | musique | 2wikimultihopqa
  context_avg_len: 512
  context_max_length: 1300
  conversation_max_length: 128
  max_new_tokens: 512
  save_path: "experiments/lora_finetune/results/${name}"
  batch_size: 1             # must stay 1 for per-sample fine-tuning
  num_workers: 2

optim:
  adapter_reg: 0.0

# ─────────────────────────────────────────────────────────────────────────────
# New section: controls the fine-tuning experiment
# ─────────────────────────────────────────────────────────────────────────────
lora_finetune:
  lr: 0.00001                        # Adam lr — 1e-5; conservative for CLM to avoid disturbing QA basin
  eval_at: [0, 1, 2, 3, 5, 10]      # finer granularity in early steps where changes are largest
  num_samples: 20                    # start small to validate before full 200-sample run
  recon_mode: "clm"                  # "clm" (plain next-token) | "recon" (chat-template reconstruction)
  recon_context_max_length: 1300     # max tokens for evidence (used by both clm and recon)
  recon_conversation_max_length: 1600 # max tokens for full RECON label (recon mode only)
  out_dir: "experiments/lora_finetune/results/${name}/${test.source}"

hidden_size: -1
num_layers: -1
num_mem_token: 4

hydra:
  job:
    chdir: false
  run:
    dir: "experiments/lora_finetune/runs/${name}/${now:%Y-%m-%d_%H-%M-%S}"
  output_subdir: null
